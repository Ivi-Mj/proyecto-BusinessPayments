{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0mg43ShjfqBGligQRVPFm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bqpQOu4pYE7d"},"outputs":[],"source":["# Cargar conjunto de datos.\n","from sklearn import datasets\n","digits = datasets.load_digits()"]},{"cell_type":"code","source":["# Verificar el formato de los datos.\n","X, y = digits.data, digits.target\n","print(X.shape)\n","print(y.shape)"],"metadata":{"id":"Ipb5v7MBYIGk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline\n","# La imagen original del dígito ha sido aplanada, por lo que la\n","volvemos a dar forma a su forma original\n","# Verificar la dimensionalidad de los datos, por ejemplo, el primer\n","elemento en el conjunto de datos X[0]\n","print(X[0].shape)\n","print(X[0])\n","# Reajustar a 8x8 para recuperar la imagen original\n","print(X[0].reshape((8,8)))"],"metadata":{"id":"g5qr1H2rYIJD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importar la biblioteca matplotlib para la visualización.\n","import matplotlib.pyplot as plt\n","# Mostrar la imagen del séptimo dígito en el conjunto de datos.\n","# Primero, reajustamos los datos del dígito a su forma original de 8x8\n","píxeles.\n","# Utilizamos 'cmap=\"gray\"' para mostrar la imagen en escala de grises.\n","# El parámetro 'interpolation=\"nearest\"' asegura que la imagen no sea\n","suavizada.\n","plt.imshow(X[6].reshape((8,8)), cmap=\"gray\", interpolation=\"nearest\")"],"metadata":{"id":"HctfWbL2YILb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importar la biblioteca matplotlib para la visualización.\n","import matplotlib.pyplot as plt\n","# Crear una figura con una cuadrícula de subplots de 8 filas por 12\n","columnas.\n","fig, ax = plt.subplots(8, 12, subplot_kw={'xticks':[], 'yticks':[]})\n","# Iterar sobre cada subplot en la cuadrícula.\n","for i in range(ax.size):\n"," # Mostrar la imagen del dígito en la posición 'i' en el conjunto\n","de datos.\n"," # Primero, reajustamos los datos del dígito a su forma original de\n","8x8 píxeles.\n"," # Utilizamos 'cmap=plt.cm.binary' para mostrar la imagen en una\n","escala de grises binaria.\n"," ax.flat[i].imshow(digits.data[i].reshape(8, 8),\n","cmap=plt.cm.binary)\n","# Ajustar el tamaño de la figura para que sea de 10 pulgadas de ancho\n","y 6 pulgadas de alto.\n","fig.set_size_inches((10, 6))"],"metadata":{"id":"e2ThoGXTYIOL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Implementación de SVM**"],"metadata":{"id":"1WvV7DuqYX1D"}},{"cell_type":"code","source":["# Importar las bibliotecas necesarias\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","import matplotlib.pyplot as plt\n","import numpy as np\n","# Cargar el conjunto de datos Iris\n","iris = load_iris()\n","X0_svm = iris.data[:, :2] # Usar solo las dos primeras\n","características para graficar\n","y0_svm = iris.target\n","# Dividir en conjunto de entrenamiento y prueba\n","X_train_svm, X_test_svm, y_train_svm, y_test_svm =\n","train_test_split(X0_svm, y0_svm, test_size=0.3, random_state=42)\n","# Entrenar un modelo SVM con kernel RBF\n","svm_model = SVC(kernel='rbf', C=1, gamma=0.1, probability=True)\n","svm_model.fit(X_train_svm, y_train_svm)\n","# Visualizar el espacio de decisión\n","h_svm = 0.02\n","x_min_svm, x_max_svm = X0_svm[:, 0].min() - 1, X0_svm[:, 0].max() + 1\n","y_min_svm, y_max_svm = X0_svm[:, 1].min() - 1, X0_svm[:, 1].max() + 1\n","xx_svm, yy_svm = np.meshgrid(np.arange(x_min_svm, x_max_svm, h_svm),\n","np.arange(y_min_svm, y_max_svm, h_svm))\n","Z_svm = svm_model.predict(np.c_[xx_svm.ravel(), yy_svm.ravel()])\n","Z_svm = Z_svm.reshape(xx_svm.shape)\n","plt.figure(figsize=(8, 6))\n","plt.contourf(xx_svm, yy_svm, Z_svm, alpha=0.8, cmap='viridis')\n","plt.scatter(X_test_svm[:, 0], X_test_svm[:, 1], c=y_test_svm,\n","edgecolor='k', cmap='viridis')\n","plt.title(\"Clasificación con SVM (kernel RBF)\")\n","plt.xlabel(\"Característica 1\")\n","plt.ylabel(\"Característica 2\")\n","plt.show()"],"metadata":{"id":"eD7-ZuSJYXnT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluación del Modelo\n","Es importante evaluar el rendimiento de la SVM utilizando métricas estándar. Las métricas\n","comunes incluyen **Precisión, Recall, F1-Score, y la Matriz de Confusión**. Estas métricas se\n","derivan de los siguientes términos fundamentales:\n","Términos Fundamentales\n","1. Verdaderos Positivos (TP):\n","- Cantidad de ejemplos positivos que el modelo clasifica correctamente como\n","positivos.\n","2. Falsos Positivos (FP):\n","- Cantidad de ejemplos negativos que el modelo clasifica incorrectamente como\n","positivos.\n","3. Verdaderos Negativos (TN):\n","- Cantidad de ejemplos negativos que el modelo clasifica correctamente como\n","negativos.\n","4. Falsos Negativos (FN):\n","- Cantidad de ejemplos positivos que el modelo clasifica incorrectamente como\n","negativos.\n","\n"],"metadata":{"id":"CyI8USiZYgrT"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix,\n","roc_auc_score\n","from sklearn.preprocessing import LabelBinarizer\n","# Predicciones\n","y_pred_svm = svm_model.predict(X_test_svm)\n","# Reporte de clasificación\n","print(\"Reporte de clasificación:\")\n","print(classification_report(y_test_svm, y_pred_svm))\n","# Matriz de confusión\n","cm_svm = confusion_matrix(y_test_svm, y_pred_svm)\n","print(\"Matriz de Confusión:\")\n","print(cm_svm)\n","# AUC para cada clase (utilizando One-vs-Rest)\n","lb_svm = LabelBinarizer()\n","y_test_bin_svm = lb_svm.fit_transform(y_test_svm) # Convertir las\n","etiquetas de clase a formato binario\n","y_pred_prob_svm = svm_model.predict_proba(X_test_svm) # Obtener las\n","probabilidades de predicción\n","# Calcular el AUC para cada clase\n","auc_scores_svm = []\n","for i in range(y_test_bin_svm.shape[1]):\n"," auc_svm = roc_auc_score(y_test_bin_svm[:, i], y_pred_prob_svm[:,\n","i])\n"," auc_scores_svm.append(auc_svm)\n","# Mostrar AUC para cada clase\n","for i, auc_svm in enumerate(auc_scores_svm):\n"," print(f\"AUC para la clase {i}: {auc_svm}\")"],"metadata":{"id":"j6cJiz5tYISj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Área Bajo la Curva ROC (AUC)"],"metadata":{"id":"7abUOWHpZBfz"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","# Definir el espacio de búsqueda\n","param_grid_svm = {\n"," 'C': [0.1, 1, 10, 100],\n"," 'gamma': [1, 0.1, 0.01, 0.001],\n"," 'kernel': ['rbf']\n","}\n","# Búsqueda en cuadrícula\n","grid_svm = GridSearchCV(SVC(), param_grid_svm, refit=True, verbose=2,\n","cv=5)\n","grid_svm.fit(X_train_svm, y_train_svm)\n","print(\"Mejores parámetros:\", grid_svm.best_params_)"],"metadata":{"id":"CrqWVAJUYIVL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Optimización Visual: Búsqueda de Kernel"],"metadata":{"id":"yKB7HAEAZJdC"}},{"cell_type":"code","source":["kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n","for kernel in kernels:\n"," svm_model = SVC(kernel=kernel, C=1, gamma='scale')\n"," svm_model.fit(X_train_svm, y_train_svm)\n"," score = svm_model.score(X_test_svm, y_test_svm)\n"," print(f\"Kernel: {kernel}, Precisión: {score}\")"],"metadata":{"id":"lqERwVR6YIXj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Clasificador K-Nearest Neighbors (KNN) con k=10\n"],"metadata":{"id":"nN4ib69EZPyq"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# Cargar el conjunto de datos Iris\n","# El conjunto de datos Iris tiene 150 muestras de 3 clases, con 4\n","características.\n","iris_knn = load_iris()\n","X0_knn = iris_knn.data[:, :2] # Tomamos solo las dos primeras\n","características para facilitar la visualización 2D\n","y0_knn = iris_knn.target\n","# Dividir en conjunto de entrenamiento y prueba\n","# test_size: Proporción del conjunto de prueba (30% de las muestras se\n","utilizan para pruebas).\n","# random_state: Aleatoriedad para asegurar divisiones reproducibles.\n","X_train_knn, X_test_knn, y_train_knn, y_test_knn =\n","train_test_split(X0_knn, y0_knn, test_size=0.3, random_state=42)\n","# Entrenar el clasificador KNN\n","# n_neighbors: Número de vecinos a considerar (k=10 en este caso).\n","knn_model = KNeighborsClassifier(n_neighbors=10)\n","knn_model.fit(X_train_knn, y_train_knn)\n","# Visualizar los resultados\n","# Configurar el espacio de la gráfica\n","h_knn = 0.02 # Tamaño del paso en la malla.\n","x_min_knn, x_max_knn = X0_knn[:, 0].min() - 1, X0_knn[:, 0].max() + 1\n","# Rango de valores para la característica 1.\n","y_min_knn, y_max_knn = X0_knn[:, 1].min() - 1, X0_knn[:, 1].max() + 1\n","# Rango de valores para la característica 2.\n","# Crear una malla de puntos para predecir sus etiquetas\n","xx_knn, yy_knn = np.meshgrid(np.arange(x_min_knn, x_max_knn, h_knn),\n","np.arange(y_min_knn, y_max_knn, h_knn))\n","Z_knn = knn_model.predict(np.c_[xx_knn.ravel(), yy_knn.ravel()]) #\n","Predecir para cada punto de la malla.\n","Z_knn = Z_knn.reshape(xx_knn.shape) # Dar forma a las predicciones\n","para que coincidan con la malla.\n","# Graficar el resultado\n","plt.figure(figsize=(8, 6))\n","plt.contourf(xx_knn, yy_knn, Z_knn, alpha=0.8, cmap='viridis') #\n","Fondo que indica la clasificación predicha.\n","plt.scatter(X_test_knn[:, 0], X_test_knn[:, 1], c=y_test_knn,\n","edgecolor='k', cmap='viridis') # Puntos del conjunto de prueba.\n","plt.title(\"Clasificación con KNN ($k=10$)\")\n","plt.xlabel(\"Característica 1\")\n","plt.ylabel(\"Característica 2\")\n","plt.show()"],"metadata":{"id":"UECXL-v4YIZ8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluación del Modelo\n"],"metadata":{"id":"yco36e6TZ3Fy"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix,\n","roc_auc_score\n","from sklearn.preprocessing import LabelBinarizer\n","# Predicciones\n","y_pred_knn = knn_model.predict(X_test_knn)\n","# Reporte de clasificación\n","print(\"Reporte de clasificación:\")\n","print(classification_report(y_test_knn, y_pred_knn))\n","# Matriz de confusión\n","cm_knn = confusion_matrix(y_test_knn, y_pred_knn)\n","print(\"Matriz de Confusión:\")\n","print(cm_knn)\n","# AUC para cada clase (utilizando One-vs-Rest)\n","lb_knn = LabelBinarizer()\n","y_test_bin_knn = lb_knn.fit_transform(y_test_knn) # Convertir las\n","etiquetas de clase a formato binario\n","y_pred_prob_knn = knn_model.predict_proba(X_test_knn) # Obtener las\n","probabilidades de predicción\n","# Calcular el AUC para cada clase\n","auc_scores_knn = []\n","for i in range(y_test_bin_knn.shape[1]):\n"," auc = roc_auc_score(y_test_bin_knn[:, i], y_pred_prob_knn[:, i])\n"," auc_scores_knn.append(auc)\n","# Mostrar AUC para cada clase\n","for i, auc in enumerate(auc_scores_knn):\n"," print(f\"AUC para la clase {i}: {auc}\")"],"metadata":{"id":"5xpg1ly4YIcb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Optimización de k**\n","\n","1. Validación Cruzada:\n"," - Probar diferentes valores de k usando validación cruzada y seleccionar el que\n","maximice la precisión promedio.\n","2. Regla General:\n"," - Un valor común es √n, donde n es el número de muestras en el conjunto de\n","entrenamiento.\n","\n","\n"],"metadata":{"id":"TAlwCLa3Z-cS"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","import numpy as np\n","# Probar diferentes valores de k\n","k_values_knn = range(1, 20)\n","accuracies_knn = []\n","for k_knn in k_values_knn:\n"," knn_model = KNeighborsClassifier(n_neighbors=k_knn)\n"," scores_knn = cross_val_score(knn_model, X_train_knn, y_train_knn,\n","cv=5)\n"," accuracies_knn.append(scores_knn.mean())\n","# Graficar la precisión promedio para diferentes valores de k\n","plt.figure(figsize=(8, 6))\n","plt.plot(k_values_knn, accuracies_knn, marker='o')\n","plt.title(\"Optimización del parámetro $k$\")\n","plt.xlabel(\"Número de vecinos ($k$)\")\n","plt.ylabel(\"Precisión promedio\")\n","plt.show()"],"metadata":{"id":"e2bxEUUrZ2qq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pasos del Algoritmo KNN"],"metadata":{"id":"sXOw8v5naS_6"}},{"cell_type":"code","source":["# Importar el módulo de vecinos (neighbors) de scikit-learn, que\n","contiene algoritmos para clasificación y regresión basados en vecinos\n","más cercanos.\n","from sklearn import neighbors\n","# Crear una instancia del clasificador K-Nearest Neighbors (KNN) con\n","k=10 vecinos.\n","knn = neighbors.KNeighborsClassifier(n_neighbors=10)\n","# Entrenar el clasificador KNN utilizando el método fit(), que ajusta\n","el modelo según los datos de entrenamiento X y las etiquetas y.\n","knn.fit(X, y)\n","KNeighborsClassifier(n_neighbors=10)"],"metadata":{"id":"_NA8KFq2YIe7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importar el módulo pickle, que se utiliza para serializar y\n","deserializar objetos de Python.\n","import pickle\n","# Abrir un archivo en modo escritura binaria ('wb') para guardar el\n","clasificador.\n","ofname = open('my_classifier.pkl', 'wb')\n","# Serializar el clasificador KNN y guardarlo en el archivo.\n","s = pickle.dump(knn, ofname)\n","# Cerrar el archivo para asegurarse de que los datos se escriben\n","correctamente.\n","ofname.close()\n","# Imprimir el resultado de la operación de dump (debería ser None).\n","print(s)\n","# Limpiar el espacio de nombres de la sesión actual.\n","%reset -f"],"metadata":{"id":"tSZeG4aqYIhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importar los módulos necesarios\n","from sklearn import neighbors\n","from sklearn import datasets\n","import pickle\n","# Abrir el archivo 'my_classifier.pkl' en modo lectura binaria ('rb')\n","para cargar el modelo guardado.\n","ofname = open('my_classifier.pkl', 'rb')\n","# Cargar el conjunto de datos de dígitos de sklearn para utilizarlo en\n","la evaluación del modelo.\n","digits = datasets.load_digits()\n","X = digits.data # Cargar las características (imágenes aplanadas de\n","los dígitos)\n","# Cargar el modelo KNN previamente guardado en el archivo\n","'my_classifier.pkl'.\n","knn = pickle.load(ofname)\n","# Cerrar el archivo después de cargar el modelo para liberar recursos.\n","ofname.close()\n","# Ahora puedes utilizar el modelo cargado (knn) para hacer\n","predicciones o evaluaciones.\n","# Calcular la predicción utilizando el modelo KNN cargado.\n","# Aquí estamos prediciendo el dígito correspondiente a la primera\n","imagen en el conjunto de datos.\n","print(knn.predict(X[0,:].reshape(1, -1)))\n","# Obtener las etiquetas (valores objetivo) del conjunto de datos.\n","y = digits.target\n","y\n","# Calcular las predicciones para todo el conjunto de datos X\n","utilizando el modelo KNN cargado.\n","y_pred = knn.predict(X)\n","y_pred"],"metadata":{"id":"aWGPM2eBYIjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calcular el rendimiento del modelo KNN en el conjunto de\n","entrenamiento.\n","# ¡SI SABES LO QUE ESTÁS HACIENDO, NUNCA DEBES HACER ESTO DE NUEVO!\n","knn.score(X, y)\n","0.9855314412910406"],"metadata":{"id":"FQ6FCHb2YImT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Clasificador de Árbol de Decisión"],"metadata":{"id":"noxE4wQ_al9B"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier, plot_tree\n","import matplotlib.pyplot as plt\n","# Cargar el conjunto de datos Iris\n","iris_dtc = load_iris()\n","X0_dtc = iris_dtc.data\n","y0_dtc = iris_dtc.target\n","# Dividir los datos en conjunto de entrenamiento y prueba\n","X_train_dtc, X_test_dtc, y_train_dtc, y_test_dtc =\n","train_test_split(X0_dtc, y0_dtc, test_size=0.3, random_state=42)\n","# Entrenar el modelo de árbol de decisión\n","dtc_model = DecisionTreeClassifier(random_state=42)\n","dtc_model.fit(X_train_dtc, y_train_dtc)\n","# Visualizar el árbol de decisión\n","plt.figure(figsize=(12, 8))\n","plot_tree(dtc_model, filled=True,\n","feature_names=iris_dtc.feature_names,\n","class_names=iris_dtc.target_names)\n","plt.title(\"Árbol de Decisión para el Conjunto de Datos Iris\")\n","plt.show()"],"metadata":{"id":"cTaVzWhVYIo7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluación del Modelo"],"metadata":{"id":"q5c0NMTTastB"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix,\n","roc_auc_score\n","from sklearn.preprocessing import LabelBinarizer\n","# Predicciones\n","y_pred_dtc = dtc_model.predict(X_test_dtc)\n","# Reporte de clasificación\n","print(\"Reporte de clasificación:\")\n","print(classification_report(y_test_dtc, y_pred_dtc))\n","# Matriz de confusión\n","cm_dtc = confusion_matrix(y_test_dtc, y_pred_dtc)\n","print(\"Matriz de Confusión:\")\n","print(cm_dtc)\n","# AUC para cada clase (utilizando One-vs-Rest)\n","lb_dtc = LabelBinarizer()\n","y_test_bin_dtc = lb_dtc.fit_transform(y_test_dtc) # Convertir las\n","etiquetas de clase a formato binario\n","y_pred_prob_dtc = dtc_model.predict_proba(X_test_dtc) # Obtener las\n","probabilidades de predicción\n","# Calcular el AUC para cada clase\n","auc_scores_dtc = []\n","for i in range(y_test_bin_dtc.shape[1]):\n"," auc = roc_auc_score(y_test_bin_dtc[:, i], y_pred_prob_dtc[:, i])\n"," auc_scores_dtc.append(auc)\n","# Mostrar AUC para cada clase\n","for i, auc in enumerate(auc_scores_dtc):\n"," print(f\"AUC para la clase {i}: {auc}\")"],"metadata":{"id":"7kUFMuV-anZh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Optimización del Árbol de Decisión"],"metadata":{"id":"ccO4c0r1a4UJ"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report, confusion_matrix,\n","roc_auc_score\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.tree import DecisionTreeClassifier\n","# Definir los hiperparámetros a ajustar\n","param_grid_dtc = {\n"," 'max_depth': [3, 5, 7, 10],\n"," 'min_samples_split': [2, 5, 10],\n"," 'min_samples_leaf': [1, 2, 4]\n","}\n","# Realizar búsqueda en cuadrícula con validación cruzada\n","grid_search_dtc =\n","GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dtc,\n","cv=5)\n","grid_search_dtc.fit(X_train_dtc, y_train_dtc)\n","# Mejor conjunto de hiperparámetros\n","print(f\"Mejores hiperparámetros: {grid_search_dtc.best_params_}\")\n","# Evaluar el modelo con los mejores parámetros\n","best_clf_dtc = grid_search_dtc.best_estimator_\n","y_pred_best_dtc = best_clf_dtc.predict(X_test_dtc)\n","\n","# Reporte de clasificación\n","print(\"Reporte de clasificación:\")\n","print(classification_report(y_test_dtc, y_pred_best_dtc))\n","# Matriz de confusión\n","cm_dtc = confusion_matrix(y_test_dtc, y_pred_best_dtc)\n","print(\"Matriz de Confusión:\")\n","print(cm_dtc)\n","# AUC para cada clase (utilizando One-vs-Rest)\n","lb_dtc = LabelBinarizer()\n","y_test_bin_dtc = lb_dtc.fit_transform(y_test_dtc) # Convertir las\n","etiquetas de clase a formato binario\n","y_pred_prob_dtc = best_clf_dtc.predict_proba(X_test_dtc) # Obtener\n","las probabilidades de predicción\n","# Calcular el AUC para cada clase\n","auc_scores_dtc = []\n","for i in range(y_test_bin_dtc.shape[1]):\n"," auc = roc_auc_score(y_test_bin_dtc[:, i], y_pred_prob_dtc[:, i])\n"," auc_scores_dtc.append(auc)\n","# Mostrar AUC para cada clase\n","for i, auc in enumerate(auc_scores_dtc):\n"," print(f\"AUC para la clase {i}: {auc}\")"],"metadata":{"id":"DETBltwtanbp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# EJERCICIO: Llena esta celda con la solución al ejercicio.\n","# Importar el conjunto de datos de dígitos desde sklearn\n","from sklearn import datasets\n","data = datasets.load_digits()\n","X, y = data.data, data.target # Cargar características (X) y\n","etiquetas (y)\n","# Importar los clasificadores KNN y Árbol de Decisión desde sklearn\n","from sklearn import neighbors\n","from sklearn import tree\n","## LLENA EL RESTO CON EL CÓDIGO DEL EJERCICIO\n","# Crear un clasificador KNN con k=5 vecinos\n","knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n","knn.fit(X, y) # Entrenar el clasificador KNN con los datos de\n","entrenamiento\n","# Calcular y mostrar el rendimiento del modelo KNN en el conjunto de\n","entrenamiento\n","score_knn = knn.score(X, y)\n","print(f\"Rendimiento del modelo KNN en el conjunto de entrenamiento:\n","{score_knn:.4f}\")\n","# Calcular predicciones utilizando el modelo KNN para comparar con los\n","valores originales\n","y_pred_knn = knn.predict(X)\n","# Mostrar algunos ejemplos de comparación entre valores originales y\n","predicciones por KNN\n","print(\"\\nEjemplos de comparación (valor original vs. predicción por\n","KNN):\")\n","for i in range(10): # Mostrar los primeros 10 ejemplos\n"," print(f\"Valor original: {y[i]}, Predicción KNN: {y_pred_knn[i]}\")"],"metadata":{"id":"p_ay_AzianeB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import os\n","#!pip3 install graphviz pydotplus\n","# Crear un clasificador de árbol de decisión\n","clf_tree = tree.DecisionTreeClassifier()\n","clf_tree.fit(X, y) # Entrenar el clasificador de árbol de decisión\n","con los datos de entrenamiento\n","# Calcular y mostrar el rendimiento del modelo de árbol de decisión en\n","el conjunto de entrenamiento\n","score_tree = clf_tree.score(X, y)\n","print(f\"Rendimiento del modelo de árbol de decisión en el conjunto de\n","entrenamiento: {score_tree:.4f}\")\n","# Calcular predicciones utilizando el modelo de árbol de decisión para\n","comparar con los valores originales\n","y_pred_tree = clf_tree.predict(X)\n","# Mostrar algunos ejemplos de comparación entre valores originales y\n","predicciones por árbol de decisión\n","print(\"\\nEjemplos de comparación (valor original vs. predicción por\n","Árbol de Decisión):\")\n","for i in range(10): # Mostrar los primeros 10 ejemplos\n"," print(f\"Valor o"],"metadata":{"id":"htR35IEXanga"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from skimage import io\n","import numpy as np\n","# Seleccionar el octavo dígito en el conjunto de datos y remodelarlo a\n","su forma original 8x8\n","tmp = X[7].reshape((8, 8))\n","# Visualizar el dígito original\n","print(\"Dígito Original:\")\n","# Normalizar la imagen y convertir a uint8 para evitar la advertencia\n","normalized_image = ((tmp - tmp.min()) / (tmp.max() - tmp.min()) *\n","255).astype(np.uint8)\n","io.imshow(normalized_image) # Ahora la imagen está en el rango\n","correcto\n","io.show()\n","# Visualizar el espejo horizontal del dígito original\n","print(\"Espejo Horizontal del Dígito:\")\n","# Normalizar el espejo horizontal y convertir a uint8\n","normalized_image_mirror = (((tmp[:, ::-1]) - tmp.min()) / (tmp.max() -\n","tmp.min()) * 255).astype(np.uint8)\n","io.imshow(normalized_image_mirror) # Imagen normalizada y convertida\n","a uint8\n","io.show()"],"metadata":{"id":"2RA7QjLnYIrT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cálculo de Nuevas Características:"],"metadata":{"id":"ZX0gZvbjbWt5"}},{"cell_type":"code","source":["import numpy as np\n","# Inicializar un arreglo para contener las nuevas características para\n","cada imagen.\n","Xnew = np.zeros((y.shape[0], 3))\n","for i in range(y.shape[0]):\n"," area = sum(X[i]) # Calcular la característica de área.\n"," tmp = X[i].reshape((8, 8))\n","\n"," # Calcular simetría horizontal multiplicando la imagen por su\n","espejo horizontal.\n"," symH = tmp * tmp[:, ::-1]\n","\n"," # Calcular simetría vertical multiplicando la imagen por su espejo vertical.\n"," symV = tmp * tmp[::-1, :]\n","\n"," # Almacenar las características calculadas en Xnew.\n"," Xnew[i, :] = [sum(symH.flatten()), area, sum(symV.flatten())]\n","# Imprimir las nuevas características y su forma.\n","print(\"Nuevas características calculadas:\")\n","print(Xnew)\n","print(\"Forma de Xnew:\", Xnew.shape)"],"metadata":{"id":"OtqYW6zabW2p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Guardar este conjunto de datos para uso posterior\n","import pickle\n","# Abrir un archivo en modo binario para escritura\n","ofname = open('my_digits_data.pkl', 'wb')\n","# Utilizar pickle para serializar y guardar los datos Xnew y y en el\n","archivo\n","s = pickle.dump([Xnew, y], ofname)\n","# Cerrar el archivo después de guardar\n","ofname.close()\n","# Imprimir un mensaje indicando que el guardado ha terminado\n","print('DONE')"],"metadata":{"id":"9TJZo31XbW5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","# Encontrar los índices de los dígitos 0 y 6 en las etiquetas y\n","idxA = y == 0\n","idxB = y == 6\n","# Elegir qué características trazar (seleccionar las columnas\n","correspondientes en Xnew)\n","feature1 = 1\n","feature2 = 2\n","# Graficar las características para los dígitos 0 y 6\n","plt.figure()\n","plt.scatter(Xnew[idxA, feature1], Xnew[idxA, feature2], c='blue',\n","alpha=0.2, label='Digit 0')\n","plt.scatter(Xnew[idxB, feature1], Xnew[idxB, feature2], c='red',\n","alpha=0.2, label='Digit 6')\n","plt.xlabel(f'Feature {feature1}')\n","plt.ylabel(f'Feature {feature2}')\n","plt.legend()\n","plt.title(f'Gráfico de dispersión de las características {feature1} vs\n","{feature2}')\n","plt.show()"],"metadata":{"id":"oIcz384ZbW7x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Medición de rendimiento"],"metadata":{"id":"oExfSlrMbnpB"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn import metrics\n","import numpy as np\n","def plot_confusion_matrix(y, y_pred):\n"," # Generar la matriz de confusión\n"," cm = metrics.confusion_matrix(y, y_pred)\n","\n"," # Configurar la figura y el tamaño\n"," plt.figure(figsize=(8, 6))\n","\n"," # Mostrar la matriz de confusión como una imagen de colores\n"," plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n"," plt.title('Matriz de Confusión')\n"," plt.colorbar() # Mostrar la barra de colores que representa los\n","valores\n","\n"," # Configurar etiquetas de los ejes x e y\n"," classes = np.unique(y)\n"," tick_marks = np.arange(len(classes))\n"," plt.xticks(tick_marks, classes, rotation=45)\n"," plt.yticks(tick_marks, classes)\n","\n"," # Agregar números como anotaciones de texto en cada celda\n"," threshold = cm.max() / 2. # Umbral para decidir el color del\n","texto\n"," for i, j in np.ndindex(cm.shape):\n"," plt.text(j, i, format(cm[i, j], 'd'),\n"," horizontalalignment=\"center\",\n"," color=\"white\" if cm[i, j] > threshold else \"black\")\n","\n"," # Ajustar el diseño para mejorar la legibilidad\n"," plt.tight_layout()\n","\n"," # Etiquetas de los ejes y título\n"," plt.ylabel('Etiqueta Verdadera')\n"," plt.xlabel('Etiqueta Predicha')\n","# Ejemplo de uso (suponiendo que y e y_pred están definidos en otra\n","parte del código)\n","# y e y_pred son las etiquetas verdaderas y predichas, respectivamente\n","# Métrica de precisión de clasificación\n","print(\"Precisión de clasificación:\", metrics.accuracy_score(y,\n","y_pred))\n","# Llamar a la función para graficar la matriz de confusión\n","plot_confusion_matrix(y, y_pred)\n","# Mostrar el gráfico\n","plt.show()"],"metadata":{"id":"V8DYpexybW-B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import neighbors\n","from sklearn import metrics\n","# Crear una instancia del clasificador KNeighborsClassifier con 1\n","vecino.\n","knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n","# Entrenar el clasificador en el conjunto de datos.\n","knn.fit(Xnew, y)\n","# Realizar predicciones en el conjunto de datos utilizando el modelo\n","entrenado.\n","yhat = knn.predict(Xnew)\n","# Imprimir la precisión de clasificación del modelo.\n","print(\"Precisión de clasificación:\", metrics.accuracy_score(yhat, y))\n","# Graficar la matriz de confusión para las etiquetas verdaderas y las\n","etiquetas predichas.\n","plot_confusion_matrix(y, yhat)\n","# Nota: El modelo con características (Xnew) se utiliza aquí en lugar\n","del conjunto de datos original,\n","# lo que indica que se han aplicado pasos de preprocesamiento o\n","técnicas de extracción de características al conjunto de datos\n","original."],"metadata":{"id":"IqQSV_CnbXAi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Resetear el espacio de trabajo para asegurar un entorno limpio\n","%reset -f\n","# Cargar el conjunto de datos de dígitos desde un archivo pickle\n","import pickle\n","# Abrir el archivo que contiene el conjunto de datos\n","with open('my_digits_data.pkl', 'rb') as ofname:\n","  # Cargar el conjunto de datos desde el archivo\n"," data = pickle.load(ofname)\n"," # Asignar características a X y etiquetas de destino a y\n"," X, y = data[0], data[1]\n","# Preparar el conjunto de datos para una simulación realista:\n","aleatorizarlo y dividirlo en subconjuntos de entrenamiento y prueba\n","import numpy as np\n","# Permutar aleatoriamente una secuencia de índices basada en el tamaño\n","de y\n","perm = np.random.permutation(y.size)\n","# Definir la proporción del conjunto de datos para asignar al\n","entrenamiento\n","PRC = 0.7\n","# Calcular el punto de división para dividir el conjunto de datos\n","split_point = int(np.ceil(y.shape[0] * PRC))\n","# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n","basados en el punto de división calculado\n","X_train = X[perm[:split_point]]\n","y_train = y[perm[:split_point]]\n","X_test = X[perm[split_point:]]\n","y_test = y[perm[split_point:]]\n","# Imprimir las formas de los conjuntos de entrenamiento y prueba para\n","verificar\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","# Entrenar un clasificador de Vecinos Más Cercanos (K-Nearest\n","Neighbors) en los datos de entrenamiento\n","from sklearn import neighbors\n","# Inicializar el clasificador con 1 vecino para simplicidad\n","knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n","# Ajustar el clasificador a los datos de entrenamiento\n","knn.fit(X_train, y_train)\n","# Predecir las etiquetas para el conjunto de entrenamiento y evaluar\n","el rendimiento\n","yhat = knn.predict(X_train)\n","# Importar las bibliotecas necesarias para la evaluación del\n","rendimiento\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","# Imprimir estadísticas de entrenamiento\n","print(\"\\nESTADÍSTICAS DE ENTRENAMIENTO:\")\n","print(\"Precisión de clasificación:\", metrics.accuracy_score(yhat,\n","y_train))\n","# Visualizar la matriz de confusión\n","def plot_confusion_matrix(cm, classes, title='Matriz de Confusión',\n","cmap=plt.cm.Blues):\n"," # Configurar la figura y el tamaño\n"," plt.figure(figsize=(8, 6))\n"," plt.imshow(cm, interpolation='nearest', cmap=cmap)\n"," plt.title(title)\n"," plt.colorbar()\n"," tick_marks = np.arange(len(classes))\n"," plt.xticks(tick_marks, classes, rotation=45)\n"," plt.yticks(tick_marks, classes)\n"," fmt = 'd'\n"," thresh = cm.max() / 2.\n"," for i, j in np.ndindex(cm.shape):\n"," plt.text(j, i, format(cm[i, j], fmt),\n"," horizontalalignment=\"center\",\n"," color=\"white\" if cm[i, j] > thresh else \"black\")\n"," plt.tight_layout()\n"," plt.ylabel('Etiqueta Verdadera')\n"," plt.xlabel('Etiqueta Predicha')\n"," plt.show()\n","# Generar la matriz de confusión a partir de las predicciones de los\n","datos de entrenamiento\n","cm = metrics.confusion_matrix(y_train, yhat)\n","# Llamar a la función para graficar la matriz de confusión mejorada\n","plot_confusion_matrix(cm, classes=np.unique(y_train), title=\"Matriz de\n","Confusión del Entrenamiento\")"],"metadata":{"id":"vCxiQSNmbXC5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predecir las etiquetas para el conjunto de prueba para evaluar el\n","rendimiento\n","yhat = knn.predict(X_test)\n","# Importar las bibliotecas necesarias para la evaluación del\n","rendimiento\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","import numpy as np\n","# Imprimir estadísticas de prueba\n","print(\"ESTADÍSTICAS DE PRUEBA:\")\n","print(\"Precisión de clasificación:\", metrics.accuracy_score(yhat,\n","y_test))\n","# Función para graficar la matriz de confusión con números para mayor claridad\n","def plot_confusion_matrix_with_numbers(cm, title='Matriz de\n","Confusión', cmap=plt.cm.Blues):\n"," \"\"\"\n"," Esta función grafica una matriz de confusión con los conteos\n","reales mostrados en la matriz para una mejor claridad.\n"," \"\"\"\n"," plt.figure(figsize=(8, 6))\n"," plt.imshow(cm, interpolation='nearest', cmap=cmap)\n"," plt.title(title)\n"," plt.colorbar()\n"," tick_marks = np.arange(len(np.unique(y_test)))\n"," plt.xticks(tick_marks, np.unique(y_test), rotation=45)\n"," plt.yticks(tick_marks, np.unique(y_test))\n"," # Iterar sobre las dimensiones de los datos y crear anotaciones de\n","texto.\n"," fmt = 'd' # Formato como entero decimal\n"," thresh = cm.max() / 2. # Umbral para el color del texto basado en\n","el fondo\n"," for i, j in np.ndindex(cm.shape):\n"," plt.text(j, i, format(cm[i, j], fmt),\n"," horizontalalignment=\"center\",\n"," color=\"white\" if cm[i, j] > thresh else \"black\")\n"," plt.tight_layout()\n"," plt.ylabel('Etiqueta Verdadera')\n"," plt.xlabel('Etiqueta Predicha')\n","# Generar la matriz de confusión a partir de las predicciones de los\n","datos de prueba\n","cm_test = metrics.confusion_matrix(y_test, yhat)\n","# Graficar la matriz de confusión mejorada con números para los datos\n","de prueba\n","plot_confusion_matrix_with_numbers(cm_test, \"Matriz de Confusión de\n","Prueba\")\n","plt.show()"],"metadata":{"id":"c9rKx0PobXFZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Entendiendo la Variabilidad en el Rendimiento del Modelo**"],"metadata":{"id":"Hea1JAoCcFlI"}},{"cell_type":"code","source":["from sklearn import model_selection, neighbors, metrics\n","import numpy as np\n","# Definir el tamaño del conjunto de prueba (proporción)\n","PRC = 0.3\n","# Crear un arreglo para almacenar las precisiones de clasificación\n","obtenidas en cada repetición\n","acc = np.zeros((10,))\n","# Realizar 10 repeticiones del proceso de división y evaluación\n","for i in range(10):\n"," # Dividir el conjunto de datos en conjuntos de entrenamiento y\n","prueba de manera aleatoria\n"," X_train, X_test, y_train, y_test =\n","model_selection.train_test_split(X, y, test_size=PRC, random_state=42)\n","\n"," # Inicializar el clasificador KNN con 1 vecino\n"," knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n","\n"," # Entrenar el clasificador en el conjunto de entrenamiento\n"," knn.fit(X_train, y_train)\n"," # Predecir las etiquetas para el conjunto de prueba\n"," yhat = knn.predict(X_test)\n","\n"," # Calcular la precisión de clasificación y almacenarla\n"," acc[i] = metrics.accuracy_score(yhat, y_test)\n","# Reorganizar el arreglo de precisión para mostrar los resultados de\n","manera adecuada\n","acc.shape = (1, 10)\n","# Imprimir el error esperado promedio (1 - precisión promedio)\n","print(\"Error esperado promedio: \" + str(1 - np.mean(acc[0])))"],"metadata":{"id":"BIygzDcZcFyB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Selección de Modelo"],"metadata":{"id":"USX1opYJcSNw"}},{"cell_type":"code","source":["# Importar las bibliotecas necesarias de sklearn para selección de\n","modelos, clasificadores y métricas\n","from sklearn import model_selection\n","from sklearn import neighbors\n","from sklearn import tree\n","from sklearn import svm\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","import numpy as np # Asegurarse de que numpy esté importado para\n","operaciones con matrices\n","# Definir la proporción del conjunto de datos a utilizar para pruebas\n","PRC = 0.1\n","# Inicializar una matriz para almacenar los resultados de precisión de\n","cada clasificador a través de las iteraciones\n","acc_r = np.zeros((10, 4)) # 10 iteraciones, 4 clasificadores\n","# Repetir el experimento 10 veces para obtener una distribución de\n","métricas de rendimiento\n","for i in range(10):\n"," # Dividir el conjunto de datos en conjuntos de entrenamiento y\n","prueba utilizando validación cruzada estratificada\n"," X_train, X_test, y_train, y_test =\n","model_selection.train_test_split(X, y, test_size=PRC, stratify=y)\n","\n"," # Inicializar clasificadores con configuraciones específicas\n"," nn1 = neighbors.KNeighborsClassifier(n_neighbors=1) #\n","Clasificador 1-Vecino Más Cercano\n"," nn3 = neighbors.KNeighborsClassifier(n_neighbors=3) #\n","Clasificador 3-Vecinos Más Cercanos\n"," svc = svm.SVC() # Clasificador SVM (Support Vector Machine)\n"," dt = tree.DecisionTreeClassifier() # Clasificador Árbol de\n","Decisión\n","\n"," # Entrenar cada clasificador con el conjunto de entrenamiento\n"," nn1.fit(X_train, y_train)\n"," nn3.fit(X_train, y_train)\n"," svc.fit(X_train, y_train)\n"," dt.fit(X_train, y_train)\n","\n"," # Predecir las etiquetas para el conjunto de prueba usando cada\n","clasificador entrenado\n"," yhat_nn1 = nn1.predict(X_test)\n"," yhat_nn3 = nn3.predict(X_test)\n"," yhat_svc = svc.predict(X_test)\n"," yhat_dt = dt.predict(X_test)\n","\n"," # Calcular y almacenar la precisión para cada clasificador\n"," acc_r[i][0] = metrics.accuracy_score(yhat_nn1, y_test)\n"," acc_r[i][1] = metrics.accuracy_score(yhat_nn3, y_test)\n"," acc_r[i][2] = metrics.accuracy_score(yhat_svc, y_test)\n"," acc_r[i][3] = metrics.accuracy_score(yhat_dt, y_test)\n","# Visualizar los resultados de precisión para cada clasificador\n","utilizando un gráfico de caja\n","plt.boxplot(acc_r);\n","# Superponer puntos rojos para mostrar los resultados individuales de\n","precisión para comparación visual\n","for i in range(4):\n"," xderiv = (i+1)*np.ones(acc_r[:, i].shape) + (np.random.rand(10,)-\n","0.5) * 0.1\n"," plt.plot(xderiv, acc_r[:, i], 'ro', alpha=0.3)\n","\n","# Personalizar el gráfico con etiquetas apropiadas\n","ax = plt.gca()\n","ax.set_xticklabels(['1-NN', '3-NN', 'SVM', 'Árbol de Decisión'])\n","plt.xlabel('Tipo de Clasificador')\n","plt.ylabel('Precisión')\n","plt.title('Comparación de Rendimiento de Clasificadores')\n","# Mostrar el gráfico\n","plt.show()"],"metadata":{"id":"YcN8aQDacF0j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Entendiendo las Técnicas de Validación Cruzada**"],"metadata":{"id":"VO_umBRrcfAP"}},{"cell_type":"code","source":["from sklearn import model_selection, neighbors, tree, svm, metrics\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# Inicializar una matriz para almacenar los puntajes de precisión para\n","cada pliegue y modelo\n","acc = np.zeros((10, 4)) # 10 pliegues, 4 modelos\n","# Crear un objeto KFold para validación cruzada de 10-fold\n","kf = model_selection.KFold(n_splits=10, shuffle=True)\n","# Contador de bucle\n","i = 0\n","# Iterar sobre cada pliegue definido por KFold\n","for train_index, test_index in kf.split(X):\n"," # Dividir los datos en conjuntos de entrenamiento y prueba basados\n","en el pliegue actual\n"," X_train, X_test = X[train_index], X[test_index]\n"," y_train, y_test = y[train_index], y[test_index]\n","\n"," # Inicializar clasificadores\n"," nn1 = neighbors.KNeighborsClassifier(n_neighbors=1) # 1-vecino\n","más cercano\n"," nn3 = neighbors.KNeighborsClassifier(n_neighbors=3) # 3-vecinos\n","más cercanos\n"," svc = svm.SVC() # Máquina de vectores de soporte (SVM)\n"," dt = tree.DecisionTreeClassifier() # Árbol de decisión\n","\n"," # Entrenar cada clasificador en el conjunto de entrenamiento\n"," nn1.fit(X_train, y_train)\n"," nn3.fit(X_train, y_train)\n"," svc.fit(X_train, y_train)\n"," dt.fit(X_train, y_train)\n","\n"," # Realizar predicciones en el conjunto de prueba\n"," yhat_nn1 = nn1.predict(X_test)\n"," yhat_nn3 = nn3.predict(X_test)\n"," yhat_svc = svc.predict(X_test)\n"," yhat_dt = dt.predict(X_test)\n","\n"," # Calcular y almacenar la precisión para cada clasificador\n"," acc[i][0] = metrics.accuracy_score(yhat_nn1, y_test)\n"," acc[i][1] = metrics.accuracy_score(yhat_nn3, y_test)\n"," acc[i][2] = metrics.accuracy_score(yhat_svc, y_test)\n"," acc[i][3] = metrics.accuracy_score(yhat_dt, y_test)\n","\n"," # Incrementar el contador del bucle\n"," i += 1\n","# Visualizar los puntajes de precisión como un gráfico de caja para\n","cada clasificador\n","plt.boxplot(acc)\n","# Superponer los puntajes individuales de precisión como puntos rojos\n","para una mejor visualización\n","for i in range(4):\n"," xderiv = (i+1) * np.ones(acc[:, i].shape) + (np.random.rand(10,) -\n","0.5) * 0.1\n"," plt.plot(xderiv, acc[:, i], 'ro', alpha=0.3)\n","# Configurar las etiquetas para cada clasificador en el eje x\n","ax = plt.gca()\n","ax.set_xticklabels(['1-NN', '3-NN', 'SVM', 'Árbol de Decisión'])\n","plt.xlabel('Tipo de Clasificador')\n","plt.ylabel('Precisión')\n","plt.title('Resultados de Validación Cruzada de 10-Fold')\n","plt.show()"],"metadata":{"id":"j4AV5WAIcF3B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Union de graficos"],"metadata":{"id":"Rl625cm7cqpv"}},{"cell_type":"code","source":["# Solo por diversión, vamos a juntar ambos gráficos\n","fig = plt.figure()\n","ax = plt.gca()\n","# Iterar sobre cada clasificador\n","for i in range(4):\n"," # Graficar el gráfico de caja para los resultados de validación\n","cruzada y repetición\n"," plt.boxplot([acc[:,i], acc_r[:,i]], positions=[2*i+1, 2*i+2],\n","widths=0.6)\n"," # Graficar los puntos individuales de precisión para validación cruzada (rojo) y repetición (azul)\n"," xderiv = (2*i+1) * np.ones(acc[:,i].shape) + (np.random.rand(10,) - 0.5) * 0.1\n"," plt.plot(xderiv, acc[:,i], 'ro', alpha=0.3)\n"," xderiv = (2*i+2) * np.ones(acc[:,i].shape) + (np.random.rand(10,) - 0.5) * 0.1\n"," plt.plot(xderiv, acc_r[:,i], 'bo', alpha=0.3)\n","# Establecer límites y etiquetas de los ejes\n","plt.xlim(0, 9)\n","plt.ylim(0, 0.4)\n","ax.set_xticklabels(['1-NN', '1-NN', '3-NN', '3-NN', 'SVM', 'SVM', 'Árbol de Decisión', 'Árbol de Decisión'], rotation=45, ha=\"right\")\n","\n","# Mostrar el gráfico\n","plt.show()"],"metadata":{"id":"O-AfZPlRcF5g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"W0oet2FQYIt8"},"execution_count":null,"outputs":[]}]}